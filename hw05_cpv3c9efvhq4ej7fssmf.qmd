---
title: "Homework Assignment: Sentiment Analysis of Emma"
format: html
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo       = TRUE, 
                      fig.align  = "center",
                      fig.height = 3, fig.width = 4)
ggplot2::theme_set(ggplot2::theme_bw() + ggplot2::theme(strip.background = ggplot2::element_rect(fill = "white")))
library(janeaustenr)
library(tidytext)
library(gutenbergr)
library(wordcloud)
library(tidyverse)
library(textdata)
```

**Title**: Exploring Joyful Language in Jane Austen’s *Emma* using Tidytext

**Objective**:

Use the **`tidytext`** package and three different **sentiment lexicons** (`nrc`, `afinn`, `bing`) to explore **positive/joyful words** in *Emma* by Jane Austen. You will tokenize the text, apply sentiment filters, visualize frequent sentiment words using `ggplot2`, and create a word cloud.

# **1. Data Preparation**

-   Load the `austen_books()` dataset from the **`janeaustenr`** package.
-   Group by book and detect chapter boundaries using regex.
-   Create `linenumber` and `chapter` columns.

```{r}
austen <- austen_books() %>% 
  group_by(book) %>% 
  mutate(
    linenumber = row_number(),
    chapter = cumsum(str_detect(
      text,
      regex("^chapter [\\divxlc]",
        ignore_case = TRUE
      )
    )),
    .before = text
  ) %>% 
  ungroup() %>% 
  select(book, chapter, linenumber, text)
```

# **2. Tokenization**

-   Use `unnest_tokens()` to tokenize text into individual words.
-   Explain briefly **why we name the output column `word`** (include this as a comment in your script).

```{r}
tidy_austen <- austen %>% 
  unnest_tokens(word, text) %>%
  mutate(word = str_extract(word, "[a-z']+")) %>% #output column is named "word" because the tokenization is performed by unit of word, rather than other unit (e.g. sentence, paragraph, etc.)
  anti_join(stop_words, by = "word") ## filter out stop words

tidy_austen %>% slice_sample(n = 5)
```

# **3. Sentiment Analysis**

## Filter joy/positive words from **each** of the three sentiment lexicons:

-   `nrc` (joy)

    ```{r}
    # nrc sentiment lexicon (one of ten emotions)
    nrc_austen <- tidy_austen %>% 
      filter(word %in% get_sentiments("nrc")$word[(str_detect(get_sentiments("nrc")$sentiment, "joy"))]) ## subsets get_sentiments to only joy terms, then uses this to filter the austen tokens

    nrc_austen
    ```

-   `afinn` (positive scores ≥ 1)

    ```{r}
    # afinn sentiment lexicon (values from -5 to +5)
    afinn_austen <- tidy_austen %>% 
      filter(word %in% (get_sentiments("afinn") %>% ## different approach here, used pipe instead of subset
                        filter(value >= 1) %>% 
                        pull(word)
                      )
      )

    afinn_austen
    ```

-   `bing` (positive)

    ```{r}
    # bing sentiment lexicon (positive or negative)
    bing_austen <- tidy_austen %>% 
      filter(word %in% (get_sentiments("bing") %>%
                        filter(sentiment == "positive") %>% 
                        pull(word)
                      )
      )

    bing_austen
    ```

## Join each with *Emma*'s text and:

-   Count word frequency.
-   Filter for frequently occurring words (`n > 50`).
-   Visualize using a **bar chart** (`ggplot2`) and a **word cloud** (`wordcloud`).

### nrc

```{r}
emma_nrc <- nrc_austen %>%
  filter(book == "Emma") %>% 
  inner_join(tidy_austen, by = "word") %>% 
  group_by(word) %>% 
  count() %>% 
  arrange(desc(n)) %>% 
  filter(n > 50)

emma_nrc

# bar chart
nrc_austen %>%
  filter(book == "Emma") %>% 
  inner_join(tidy_austen, by = "word") %>% 
  group_by(word) %>% 
  count() %>% 
  filter(n > 50) %>% 
  ggplot(aes(x = word, y = n)) +
  geom_bar(stat = "identity")

# word cloud
nrc_austen %>%
  filter(book == "Emma") %>% 
  inner_join(tidy_austen, by = "word") %>% 
  group_by(word) %>% 
  count() %>% 
  filter(n > 50) %>% 
  with(wordcloud(word, n, max.words = 30))
```

### afinn

```{r}
emma_afinn <- afinn_austen %>%
  filter(book == "Emma") %>% 
  inner_join(tidy_austen, by = "word") %>% 
  group_by(word) %>% 
  count() %>% 
  arrange(desc(n)) %>% 
  filter(n > 50)

emma_afinn

# bar chart
afinn_austen %>%
  filter(book == "Emma") %>% 
  inner_join(tidy_austen, by = "word") %>% 
  group_by(word) %>% 
  count() %>% 
  filter(n > 50) %>% 
  ggplot(aes(x = word, y = n)) +
  geom_bar(stat = "identity")

# word cloud
afinn_austen %>%
  filter(book == "Emma") %>% 
  inner_join(tidy_austen, by = "word") %>% 
  group_by(word) %>% 
  count() %>% 
  filter(n > 50) %>% 
  with(wordcloud(word, n, max.words = 30))
```

### bing

```{r}
emma_bing <- bing_austen %>%
  filter(book == "Emma") %>% 
  inner_join(tidy_austen, by = "word") %>% 
  group_by(word) %>% 
  count() %>% 
  arrange(desc(n)) %>% 
  filter(n > 50)

emma_bing

# bar chart
bing_austen %>%
  filter(book == "Emma") %>% 
  inner_join(tidy_austen, by = "word") %>% 
  group_by(word) %>% 
  count() %>% 
  filter(n > 50) %>% 
  ggplot(aes(x = word, y = n)) +
  geom_bar(stat = "identity")

# word cloud
bing_austen %>%
  filter(book == "Emma") %>% 
  inner_join(tidy_austen, by = "word") %>% 
  group_by(word) %>% 
  count() %>% 
  filter(n > 50) %>% 
  with(wordcloud(word, n, max.words = 30))
```
